{"run_name": "output/default/tk-instruct-3b-def-pos", "predict_loss": 1.2119768857955933, "predict_exact_match": 36.1473, "predict_rouge1": 55.7359, "predict_rougeL": 54.3362, "predict_exact_match_for_task1356_xlsum_title_generation": 0.0, "predict_rouge1_for_task1356_xlsum_title_generation": 28.9066, "predict_rougeL_for_task1356_xlsum_title_generation": 24.3295, "predict_exact_match_for_task893_gap_fill_the_blank_coreference_resolution": 64.0, "predict_rouge1_for_task893_gap_fill_the_blank_coreference_resolution": 64.0, "predict_rougeL_for_task893_gap_fill_the_blank_coreference_resolution": 64.0, "predict_exact_match_for_task641_esnli_classification": 30.0, "predict_rouge1_for_task641_esnli_classification": 30.0, "predict_rougeL_for_task641_esnli_classification": 30.0, "predict_exact_match_for_task1529_scitail1.1_classification": 65.0, "predict_rouge1_for_task1529_scitail1.1_classification": 65.0, "predict_rougeL_for_task1529_scitail1.1_classification": 65.0, "predict_exact_match_for_task202_mnli_contradiction_classification": 60.0, "predict_rouge1_for_task202_mnli_contradiction_classification": 60.0, "predict_rougeL_for_task202_mnli_contradiction_classification": 60.0, "predict_exact_match_for_task670_ambigqa_question_generation": 1.0, "predict_rouge1_for_task670_ambigqa_question_generation": 76.4119, "predict_rougeL_for_task670_ambigqa_question_generation": 74.2359, "predict_exact_match_for_task1393_superglue_copa_text_completion": 79.0, "predict_rouge1_for_task1393_superglue_copa_text_completion": 79.0, "predict_rougeL_for_task1393_superglue_copa_text_completion": 79.0, "predict_exact_match_for_task1344_glue_entailment_classification": 65.0, "predict_rouge1_for_task1344_glue_entailment_classification": 65.0, "predict_rougeL_for_task1344_glue_entailment_classification": 65.0, "predict_exact_match_for_task288_gigaword_summarization": 0.0, "predict_rouge1_for_task288_gigaword_summarization": 33.7902, "predict_rougeL_for_task288_gigaword_summarization": 29.3317, "predict_exact_match_for_task1387_anli_r3_entailment": 17.0, "predict_rouge1_for_task1387_anli_r3_entailment": 35.0, "predict_rougeL_for_task1387_anli_r3_entailment": 35.0, "predict_exact_match_for_task1664_winobias_text_generation": 40.0, "predict_rouge1_for_task1664_winobias_text_generation": 72.9905, "predict_rougeL_for_task1664_winobias_text_generation": 72.9905, "predict_exact_match_for_task1161_coda19_title_generation": 1.0, "predict_rouge1_for_task1161_coda19_title_generation": 43.2719, "predict_rougeL_for_task1161_coda19_title_generation": 35.8028, "predict_exact_match_for_task880_schema_guided_dstc8_classification": 46.0, "predict_rouge1_for_task880_schema_guided_dstc8_classification": 49.3333, "predict_rougeL_for_task880_schema_guided_dstc8_classification": 49.3333, "predict_exact_match_for_task738_perspectrum_classification": 36.0, "predict_rouge1_for_task738_perspectrum_classification": 83.0, "predict_rougeL_for_task738_perspectrum_classification": 83.0, "predict_exact_match_for_task1439_doqa_cooking_isanswerable": 64.0, "predict_rouge1_for_task1439_doqa_cooking_isanswerable": 64.0, "predict_rougeL_for_task1439_doqa_cooking_isanswerable": 64.0, "predict_exact_match_for_task645_summarization": 88.0, "predict_rouge1_for_task645_summarization": 95.3524, "predict_rougeL_for_task645_summarization": 95.3524, "predict_exact_match_for_task619_ohsumed_abstract_title_generation": 0.0, "predict_rouge1_for_task619_ohsumed_abstract_title_generation": 49.1018, "predict_rougeL_for_task619_ohsumed_abstract_title_generation": 40.4849, "predict_exact_match_for_task1728_web_nlg_data_to_text": 6.0, "predict_rouge1_for_task1728_web_nlg_data_to_text": 63.816, "predict_rougeL_for_task1728_web_nlg_data_to_text": 55.498, "predict_exact_match_for_task1640_aqa1.0_answerable_unanswerable_question_classification": 72.0, "predict_rouge1_for_task1640_aqa1.0_answerable_unanswerable_question_classification": 72.0, "predict_rougeL_for_task1640_aqa1.0_answerable_unanswerable_question_classification": 72.0, "predict_exact_match_for_task648_answer_generation": 18.0, "predict_rouge1_for_task648_answer_generation": 43.3, "predict_rougeL_for_task648_answer_generation": 43.3, "predict_exact_match_for_task242_tweetqa_classification": 99.0, "predict_rouge1_for_task242_tweetqa_classification": 99.0, "predict_rougeL_for_task242_tweetqa_classification": 99.0, "predict_exact_match_for_task620_ohsumed_medical_subject_headings_answer_generation": 25.0, "predict_rouge1_for_task620_ohsumed_medical_subject_headings_answer_generation": 51.8167, "predict_rougeL_for_task620_ohsumed_medical_subject_headings_answer_generation": 50.1667, "predict_exact_match_for_task1159_bard_analogical_reasoning_containers": 37.0, "predict_rouge1_for_task1159_bard_analogical_reasoning_containers": 37.6667, "predict_rougeL_for_task1159_bard_analogical_reasoning_containers": 37.6667, "predict_exact_match_for_task500_scruples_anecdotes_title_generation": 2.0, "predict_rouge1_for_task500_scruples_anecdotes_title_generation": 23.9117, "predict_rougeL_for_task500_scruples_anecdotes_title_generation": 22.2243, "predict_exact_match_for_task890_gcwd_classification": 53.0, "predict_rouge1_for_task890_gcwd_classification": 53.0, "predict_rougeL_for_task890_gcwd_classification": 53.0, "predict_exact_match_for_task039_qasc_find_overlapping_words": 37.0, "predict_rouge1_for_task039_qasc_find_overlapping_words": 45.5, "predict_rougeL_for_task039_qasc_find_overlapping_words": 45.5, "predict_exact_match_for_task1154_bard_analogical_reasoning_travel": 28.0, "predict_rouge1_for_task1154_bard_analogical_reasoning_travel": 28.0, "predict_rougeL_for_task1154_bard_analogical_reasoning_travel": 28.0, "predict_exact_match_for_task1612_sick_label_classification": 52.0, "predict_rouge1_for_task1612_sick_label_classification": 52.0, "predict_rougeL_for_task1612_sick_label_classification": 52.0, "predict_exact_match_for_task1442_doqa_movies_isanswerable": 64.0, "predict_rouge1_for_task1442_doqa_movies_isanswerable": 64.0, "predict_rougeL_for_task1442_doqa_movies_isanswerable": 64.0, "predict_exact_match_for_task233_iirc_link_exists_classification": 50.0, "predict_rouge1_for_task233_iirc_link_exists_classification": 50.0, "predict_rougeL_for_task233_iirc_link_exists_classification": 50.0, "predict_exact_match_for_task936_defeasible_nli_snli_classification": 71.0, "predict_rouge1_for_task936_defeasible_nli_snli_classification": 71.0, "predict_rougeL_for_task936_defeasible_nli_snli_classification": 71.0, "predict_exact_match_for_task1386_anli_r2_entailment": 18.0, "predict_rouge1_for_task1386_anli_r2_entailment": 39.0, "predict_rougeL_for_task1386_anli_r2_entailment": 39.0, "predict_exact_match_for_task1152_bard_analogical_reasoning_causation": 27.0, "predict_rouge1_for_task1152_bard_analogical_reasoning_causation": 27.0, "predict_rougeL_for_task1152_bard_analogical_reasoning_causation": 27.0, "predict_exact_match_for_task290_tellmewhy_question_answerability": 50.0, "predict_rouge1_for_task290_tellmewhy_question_answerability": 83.3333, "predict_rougeL_for_task290_tellmewhy_question_answerability": 83.3333, "predict_exact_match_for_task304_numeric_fused_head_resolution": 4.0, "predict_rouge1_for_task304_numeric_fused_head_resolution": 4.0, "predict_rougeL_for_task304_numeric_fused_head_resolution": 4.0, "predict_exact_match_for_task760_msr_sqa_long_text_generation": 0.0, "predict_rouge1_for_task760_msr_sqa_long_text_generation": 5.9086, "predict_rougeL_for_task760_msr_sqa_long_text_generation": 5.387, "predict_exact_match_for_task035_winogrande_question_modification_person": 9.0, "predict_rouge1_for_task035_winogrande_question_modification_person": 89.283, "predict_rougeL_for_task035_winogrande_question_modification_person": 88.6233, "predict_exact_match_for_task569_recipe_nlg_text_generation": 6.0, "predict_rouge1_for_task569_recipe_nlg_text_generation": 42.6867, "predict_rougeL_for_task569_recipe_nlg_text_generation": 41.5541, "predict_exact_match_for_task391_causal_relationship": 57.0, "predict_rouge1_for_task391_causal_relationship": 85.6667, "predict_rougeL_for_task391_causal_relationship": 85.6667, "predict_exact_match_for_task891_gap_coreference_resolution": 60.0, "predict_rouge1_for_task891_gap_coreference_resolution": 68.2667, "predict_rougeL_for_task891_gap_coreference_resolution": 68.2667, "predict_exact_match_for_task1586_scifact_title_generation": 0.0, "predict_rouge1_for_task1586_scifact_title_generation": 42.79, "predict_rougeL_for_task1586_scifact_title_generation": 36.192, "predict_exact_match_for_task602_wikitext-103_answer_generation": 5.9524, "predict_rouge1_for_task602_wikitext-103_answer_generation": 15.9984, "predict_rougeL_for_task602_wikitext-103_answer_generation": 15.9984, "predict_exact_match_for_task1195_disflqa_disfluent_to_fluent_conversion": 10.0, "predict_rouge1_for_task1195_disflqa_disfluent_to_fluent_conversion": 82.0872, "predict_rougeL_for_task1195_disflqa_disfluent_to_fluent_conversion": 81.4343, "predict_exact_match_for_task1409_dart_text_generation": 3.0, "predict_rouge1_for_task1409_dart_text_generation": 50.5904, "predict_rougeL_for_task1409_dart_text_generation": 42.7583, "predict_exact_match_for_task033_winogrande_answer_generation": 59.0, "predict_rouge1_for_task033_winogrande_answer_generation": 61.6667, "predict_rougeL_for_task033_winogrande_answer_generation": 61.6667, "predict_exact_match_for_task1407_dart_question_generation": 0.0, "predict_rouge1_for_task1407_dart_question_generation": 25.0024, "predict_rougeL_for_task1407_dart_question_generation": 19.7616, "predict_exact_match_for_task402_grailqa_paraphrase_generation": 4.0, "predict_rouge1_for_task402_grailqa_paraphrase_generation": 75.0216, "predict_rougeL_for_task402_grailqa_paraphrase_generation": 62.9062, "predict_exact_match_for_task201_mnli_neutral_classification": 15.0, "predict_rouge1_for_task201_mnli_neutral_classification": 15.0, "predict_rougeL_for_task201_mnli_neutral_classification": 15.0, "predict_exact_match_for_task520_aquamuse_answer_given_in_passage": 90.0, "predict_rouge1_for_task520_aquamuse_answer_given_in_passage": 90.0, "predict_rougeL_for_task520_aquamuse_answer_given_in_passage": 90.0, "predict_exact_match_for_task892_gap_reverse_coreference_resolution": 44.0, "predict_rouge1_for_task892_gap_reverse_coreference_resolution": 44.0, "predict_rougeL_for_task892_gap_reverse_coreference_resolution": 44.0, "predict_exact_match_for_task828_copa_commonsense_cause_effect": 70.0, "predict_rouge1_for_task828_copa_commonsense_cause_effect": 70.0, "predict_rougeL_for_task828_copa_commonsense_cause_effect": 70.0, "predict_exact_match_for_task769_qed_summarization": 69.0, "predict_rouge1_for_task769_qed_summarization": 89.6629, "predict_rougeL_for_task769_qed_summarization": 89.6629, "predict_exact_match_for_task1155_bard_analogical_reasoning_trash_or_treasure": 80.0, "predict_rouge1_for_task1155_bard_analogical_reasoning_trash_or_treasure": 80.0, "predict_rougeL_for_task1155_bard_analogical_reasoning_trash_or_treasure": 80.0, "predict_exact_match_for_task1385_anli_r1_entailment": 5.0, "predict_rouge1_for_task1385_anli_r1_entailment": 33.0, "predict_rougeL_for_task1385_anli_r1_entailment": 33.0, "predict_exact_match_for_task1531_daily_dialog_type_classification": 41.0, "predict_rouge1_for_task1531_daily_dialog_type_classification": 49.0, "predict_rougeL_for_task1531_daily_dialog_type_classification": 49.0, "predict_exact_match_for_task1516_imppres_naturallanguageinference": 57.0, "predict_rouge1_for_task1516_imppres_naturallanguageinference": 57.0, "predict_rougeL_for_task1516_imppres_naturallanguageinference": 57.0, "predict_exact_match_for_task1394_meta_woz_task_classification": 56.0, "predict_rouge1_for_task1394_meta_woz_task_classification": 60.8, "predict_rougeL_for_task1394_meta_woz_task_classification": 60.8, "predict_exact_match_for_task401_numeric_fused_head_reference": 34.0, "predict_rouge1_for_task401_numeric_fused_head_reference": 45.3333, "predict_rougeL_for_task401_numeric_fused_head_reference": 45.3333, "predict_exact_match_for_task1598_nyc_long_text_generation": 0.0, "predict_rouge1_for_task1598_nyc_long_text_generation": 31.3481, "predict_rougeL_for_task1598_nyc_long_text_generation": 25.6353, "predict_exact_match_for_task1615_sick_tclassify_b_relation_a": 50.0, "predict_rouge1_for_task1615_sick_tclassify_b_relation_a": 83.3333, "predict_rougeL_for_task1615_sick_tclassify_b_relation_a": 83.3333, "predict_exact_match_for_task970_sherliic_causal_relationship": 64.0, "predict_rouge1_for_task970_sherliic_causal_relationship": 64.0, "predict_rougeL_for_task970_sherliic_causal_relationship": 64.0, "predict_exact_match_for_task1390_wscfixed_coreference": 50.0, "predict_rouge1_for_task1390_wscfixed_coreference": 50.0, "predict_rougeL_for_task1390_wscfixed_coreference": 50.0, "predict_exact_match_for_task199_mnli_classification": 50.0, "predict_rouge1_for_task199_mnli_classification": 50.0, "predict_rougeL_for_task199_mnli_classification": 50.0, "predict_exact_match_for_task034_winogrande_question_modification_object": 9.0, "predict_rouge1_for_task034_winogrande_question_modification_object": 92.9104, "predict_rougeL_for_task034_winogrande_question_modification_object": 92.4447, "predict_exact_match_for_task133_winowhy_reason_plausibility_detection": 9.0, "predict_rouge1_for_task133_winowhy_reason_plausibility_detection": 9.0, "predict_rougeL_for_task133_winowhy_reason_plausibility_detection": 9.0, "predict_exact_match_for_task226_english_language_answer_relevance_classification": 54.0, "predict_rouge1_for_task226_english_language_answer_relevance_classification": 54.0, "predict_rougeL_for_task226_english_language_answer_relevance_classification": 54.0, "predict_exact_match_for_task510_reddit_tifu_title_summarization": 2.0, "predict_rouge1_for_task510_reddit_tifu_title_summarization": 40.9796, "predict_rougeL_for_task510_reddit_tifu_title_summarization": 39.7662, "predict_exact_match_for_task935_defeasible_nli_atomic_classification": 64.0, "predict_rouge1_for_task935_defeasible_nli_atomic_classification": 64.0, "predict_rougeL_for_task935_defeasible_nli_atomic_classification": 64.0, "predict_exact_match_for_task349_squad2.0_answerable_unanswerable_question_classification": 53.0, "predict_rouge1_for_task349_squad2.0_answerable_unanswerable_question_classification": 53.0, "predict_rougeL_for_task349_squad2.0_answerable_unanswerable_question_classification": 53.0, "predict_exact_match_for_task1157_bard_analogical_reasoning_rooms_for_containers": 60.0, "predict_rouge1_for_task1157_bard_analogical_reasoning_rooms_for_containers": 60.0, "predict_rougeL_for_task1157_bard_analogical_reasoning_rooms_for_containers": 60.0, "predict_exact_match_for_task937_defeasible_nli_social_classification": 54.0, "predict_rouge1_for_task937_defeasible_nli_social_classification": 56.0, "predict_rougeL_for_task937_defeasible_nli_social_classification": 56.0, "predict_exact_match_for_task743_eurlex_summarization": 2.0, "predict_rouge1_for_task743_eurlex_summarization": 39.1854, "predict_rougeL_for_task743_eurlex_summarization": 34.125, "predict_exact_match_for_task1388_cb_entailment": 33.0, "predict_rouge1_for_task1388_cb_entailment": 57.0, "predict_rougeL_for_task1388_cb_entailment": 57.0, "predict_exact_match_for_task671_ambigqa_text_generation": 0.0, "predict_rouge1_for_task671_ambigqa_text_generation": 64.7232, "predict_rougeL_for_task671_ambigqa_text_generation": 63.3193, "predict_exact_match_for_task121_zest_text_modification": 0.0, "predict_rouge1_for_task121_zest_text_modification": 49.9621, "predict_rougeL_for_task121_zest_text_modification": 44.34, "predict_exact_match_for_task1345_glue_qqp_question_paraprashing": 0.0, "predict_rouge1_for_task1345_glue_qqp_question_paraprashing": 41.6095, "predict_rougeL_for_task1345_glue_qqp_question_paraprashing": 38.8349, "predict_exact_match_for_task330_gap_answer_generation": 64.0, "predict_rouge1_for_task330_gap_answer_generation": 72.8429, "predict_rougeL_for_task330_gap_answer_generation": 72.8429, "predict_exact_match_for_task1342_amazon_us_reviews_title": 2.0, "predict_rouge1_for_task1342_amazon_us_reviews_title": 14.8492, "predict_rougeL_for_task1342_amazon_us_reviews_title": 13.987, "predict_exact_match_for_task329_gap_classification": 60.0, "predict_rouge1_for_task329_gap_classification": 60.0, "predict_rougeL_for_task329_gap_classification": 60.0, "predict_exact_match_for_task281_points_of_correspondence": 0.0, "predict_rouge1_for_task281_points_of_correspondence": 21.3362, "predict_rougeL_for_task281_points_of_correspondence": 20.7491, "predict_exact_match_for_task036_qasc_topic_word_to_generate_related_fact": 45.0, "predict_rouge1_for_task036_qasc_topic_word_to_generate_related_fact": 81.7373, "predict_rougeL_for_task036_qasc_topic_word_to_generate_related_fact": 80.3317, "predict_exact_match_for_task1554_scitail_classification": 64.0, "predict_rouge1_for_task1554_scitail_classification": 64.0, "predict_rougeL_for_task1554_scitail_classification": 64.0, "predict_exact_match_for_task050_multirc_answerability": 70.0, "predict_rouge1_for_task050_multirc_answerability": 70.0, "predict_rougeL_for_task050_multirc_answerability": 70.0, "predict_exact_match_for_task362_spolin_yesand_prompt_response_sub_classification": 53.0, "predict_rouge1_for_task362_spolin_yesand_prompt_response_sub_classification": 76.5, "predict_rougeL_for_task362_spolin_yesand_prompt_response_sub_classification": 76.5, "predict_exact_match_for_task1557_jfleg_answer_generation": 11.0, "predict_rouge1_for_task1557_jfleg_answer_generation": 86.1558, "predict_rougeL_for_task1557_jfleg_answer_generation": 85.2343, "predict_exact_match_for_task249_enhanced_wsc_pronoun_disambiguation": 46.0, "predict_rouge1_for_task249_enhanced_wsc_pronoun_disambiguation": 58.65, "predict_rougeL_for_task249_enhanced_wsc_pronoun_disambiguation": 58.65, "predict_exact_match_for_task957_e2e_nlg_text_generation_generate": 0.0, "predict_rouge1_for_task957_e2e_nlg_text_generation_generate": 57.7502, "predict_rougeL_for_task957_e2e_nlg_text_generation_generate": 43.5291, "predict_exact_match_for_task418_persent_title_generation": 2.0, "predict_rouge1_for_task418_persent_title_generation": 33.3812, "predict_rougeL_for_task418_persent_title_generation": 30.245, "predict_exact_match_for_task614_glucose_cause_event_detection": 2.0, "predict_rouge1_for_task614_glucose_cause_event_detection": 50.6197, "predict_rougeL_for_task614_glucose_cause_event_detection": 48.7934, "predict_exact_match_for_task677_ollie_sentence_answer_generation": 0.0, "predict_rouge1_for_task677_ollie_sentence_answer_generation": 30.656, "predict_rougeL_for_task677_ollie_sentence_answer_generation": 24.8026, "predict_exact_match_for_task220_rocstories_title_classification": 100.0, "predict_rouge1_for_task220_rocstories_title_classification": 100.0, "predict_rougeL_for_task220_rocstories_title_classification": 100.0, "predict_exact_match_for_task1631_openpi_answer_generation": 43.0, "predict_rouge1_for_task1631_openpi_answer_generation": 90.7, "predict_rougeL_for_task1631_openpi_answer_generation": 87.659, "predict_exact_match_for_task232_iirc_link_number_classification": 48.0, "predict_rouge1_for_task232_iirc_link_number_classification": 48.0, "predict_rougeL_for_task232_iirc_link_number_classification": 48.0, "predict_exact_match_for_task1391_winogrande_easy_answer_generation": 77.0, "predict_rouge1_for_task1391_winogrande_easy_answer_generation": 77.0, "predict_rougeL_for_task1391_winogrande_easy_answer_generation": 77.0, "predict_exact_match_for_task1358_xlsum_title_generation": 0.0, "predict_rouge1_for_task1358_xlsum_title_generation": 38.6753, "predict_rougeL_for_task1358_xlsum_title_generation": 33.1354, "predict_exact_match_for_task1533_daily_dialog_formal_classification": 55.0, "predict_rouge1_for_task1533_daily_dialog_formal_classification": 55.0, "predict_rougeL_for_task1533_daily_dialog_formal_classification": 55.0, "predict_exact_match_for_task1156_bard_analogical_reasoning_tools": 57.0, "predict_rouge1_for_task1156_bard_analogical_reasoning_tools": 57.0, "predict_rougeL_for_task1156_bard_analogical_reasoning_tools": 57.0, "predict_exact_match_for_task1659_title_generation": 6.0, "predict_rouge1_for_task1659_title_generation": 37.5335, "predict_rougeL_for_task1659_title_generation": 32.3555, "predict_exact_match_for_task1624_disfl_qa_question_yesno_classification": 67.0, "predict_rouge1_for_task1624_disfl_qa_question_yesno_classification": 67.0, "predict_rougeL_for_task1624_disfl_qa_question_yesno_classification": 67.0, "predict_exact_match_for_task1158_bard_analogical_reasoning_manipulating_items": 59.0, "predict_rouge1_for_task1158_bard_analogical_reasoning_manipulating_items": 59.0, "predict_rougeL_for_task1158_bard_analogical_reasoning_manipulating_items": 59.0, "predict_exact_match_for_task827_copa_commonsense_reasoning": 83.0, "predict_rouge1_for_task827_copa_commonsense_reasoning": 83.0, "predict_rougeL_for_task827_copa_commonsense_reasoning": 83.0, "predict_exact_match_for_task1153_bard_analogical_reasoning_affordance": 44.0, "predict_rouge1_for_task1153_bard_analogical_reasoning_affordance": 46.3333, "predict_rougeL_for_task1153_bard_analogical_reasoning_affordance": 46.3333, "predict_exact_match_for_task393_plausible_result_generation": 0.0, "predict_rouge1_for_task393_plausible_result_generation": 31.0521, "predict_rougeL_for_task393_plausible_result_generation": 30.2273, "predict_exact_match_for_task879_schema_guided_dstc8_classification": 72.0, "predict_rouge1_for_task879_schema_guided_dstc8_classification": 72.0, "predict_rougeL_for_task879_schema_guided_dstc8_classification": 72.0, "predict_exact_match_for_task613_politifact_text_generation": 10.0, "predict_rouge1_for_task613_politifact_text_generation": 20.4, "predict_rougeL_for_task613_politifact_text_generation": 20.4, "predict_exact_match_for_task219_rocstories_title_answer_generation": 2.0, "predict_rouge1_for_task219_rocstories_title_answer_generation": 20.6871, "predict_rougeL_for_task219_rocstories_title_answer_generation": 20.6871, "predict_exact_match_for_task190_snli_classification": 6.0, "predict_rouge1_for_task190_snli_classification": 6.0, "predict_rougeL_for_task190_snli_classification": 6.0, "predict_exact_match_for_task200_mnli_entailment_classification": 90.0, "predict_rouge1_for_task200_mnli_entailment_classification": 90.0, "predict_rougeL_for_task200_mnli_entailment_classification": 90.0, "predict_exact_match_for_task1534_daily_dialog_question_classification": 48.0, "predict_rouge1_for_task1534_daily_dialog_question_classification": 48.0, "predict_rougeL_for_task1534_daily_dialog_question_classification": 48.0, "predict_exact_match_for_task1540_parsed_pdfs_summarization": 1.0, "predict_rouge1_for_task1540_parsed_pdfs_summarization": 42.7164, "predict_rougeL_for_task1540_parsed_pdfs_summarization": 39.2993, "predict_exact_match_for_task442_com_qa_paraphrase_question_generation": 3.0, "predict_rouge1_for_task442_com_qa_paraphrase_question_generation": 75.7944, "predict_rougeL_for_task442_com_qa_paraphrase_question_generation": 70.3849, "predict_exact_match_for_task392_inverse_causal_relationship": 59.0, "predict_rouge1_for_task392_inverse_causal_relationship": 86.3333, "predict_rougeL_for_task392_inverse_causal_relationship": 86.3333, "predict_exact_match_for_task1562_zest_text_modification": 1.0, "predict_rouge1_for_task1562_zest_text_modification": 55.1822, "predict_rougeL_for_task1562_zest_text_modification": 48.797, "predict_exact_match_for_task640_esnli_classification": 40.0, "predict_rouge1_for_task640_esnli_classification": 40.0, "predict_rougeL_for_task640_esnli_classification": 40.0, "predict_exact_match_for_task1622_disfl_qa_text_modication": 11.0, "predict_rouge1_for_task1622_disfl_qa_text_modication": 81.5147, "predict_rougeL_for_task1622_disfl_qa_text_modication": 80.9269, "predict_exact_match_for_task623_ohsumed_yes_no_answer_generation": 73.0, "predict_rouge1_for_task623_ohsumed_yes_no_answer_generation": 73.0, "predict_rougeL_for_task623_ohsumed_yes_no_answer_generation": 73.0, "predict_exact_match_for_task020_mctaco_span_based_question": 54.0, "predict_rouge1_for_task020_mctaco_span_based_question": 54.0, "predict_rougeL_for_task020_mctaco_span_based_question": 54.0, "predict_exact_match_for_task642_esnli_classification": 44.0, "predict_rouge1_for_task642_esnli_classification": 44.0, "predict_rougeL_for_task642_esnli_classification": 44.0, "predict_exact_match_for_task102_commongen_sentence_generation": 0.0, "predict_rouge1_for_task102_commongen_sentence_generation": 68.6174, "predict_rougeL_for_task102_commongen_sentence_generation": 58.0841, "predict_exact_match_for_title_generation": 11.2108, "predict_rouge1_for_title_generation": 41.2314, "predict_rougeL_for_title_generation": 37.9272, "predict_exact_match_for_coreference_resolution": 44.9286, "predict_rouge1_for_coreference_resolution": 52.2179, "predict_rougeL_for_coreference_resolution": 52.2179, "predict_exact_match_for_textual_entailment": 45.9583, "predict_rouge1_for_textual_entailment": 53.1806, "predict_rougeL_for_textual_entailment": 53.1806, "predict_exact_match_for_question_rewriting": 4.3636, "predict_rouge1_for_question_rewriting": 71.3182, "predict_rougeL_for_question_rewriting": 67.8407, "predict_exact_match_for_cause_effect_classification": 50.0, "predict_rouge1_for_cause_effect_classification": 69.3817, "predict_rougeL_for_cause_effect_classification": 69.003, "predict_exact_match_for_dialogue_act_recognition": 53.0, "predict_rouge1_for_dialogue_act_recognition": 58.6619, "predict_rougeL_for_dialogue_act_recognition": 58.6619, "predict_exact_match_for_answerability_classification": 64.2308, "predict_rouge1_for_answerability_classification": 66.7949, "predict_rougeL_for_answerability_classification": 66.7949, "predict_exact_match_for_keyword_tagging": 48.2, "predict_rouge1_for_keyword_tagging": 64.4613, "predict_rougeL_for_keyword_tagging": 63.8502, "predict_exact_match_for_data_to_text": 6.2954, "predict_rouge1_for_data_to_text": 50.8495, "predict_rougeL_for_data_to_text": 43.478, "predict_exact_match_for_word_analogy": 49.0, "predict_rouge1_for_word_analogy": 49.375, "predict_rougeL_for_word_analogy": 49.375, "predict_exact_match_for_overlap_extraction": 18.5, "predict_rouge1_for_overlap_extraction": 33.4181, "predict_rougeL_for_overlap_extraction": 33.1246, "predict_exact_match_for_grammar_error_correction": 11.0, "predict_rouge1_for_grammar_error_correction": 86.1558, "predict_rougeL_for_grammar_error_correction": 85.2343, "predict_gen_len": 7.7789, "predict_global_step": 0, "predict_runtime": 3325.359, "predict_samples_per_second": 3.551, "predict_steps_per_second": 0.888, "predict_samples": 11810}